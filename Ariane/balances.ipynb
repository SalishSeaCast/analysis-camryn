{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arrow\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import os\n",
    "import cmocean.cm as cm\n",
    "import matplotlib.cm as cma\n",
    "import scipy.interpolate as interp\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.dates as mpl_dates\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datafile):\n",
    "    saltf = datafile.final_salt\n",
    "    transpf = datafile.final_transp\n",
    "    lonf = datafile.final_lon\n",
    "    latf = datafile.final_lat\n",
    "    depthf = datafile.final_depth\n",
    "    sectionf = datafile.final_section\n",
    "    zf = datafile.final_z\n",
    "    tempf = datafile.final_temp\n",
    "    \n",
    "    return saltf,transpf,lonf,latf,depthf,sectionf,zf,tempf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract data from 1 section\n",
    "def get_secdata(datafile,sectionnum):\n",
    "    saltf = datafile.final_salt\n",
    "    transpf = datafile.final_transp\n",
    "    lonf = datafile.final_lon\n",
    "    latf = datafile.final_lat\n",
    "    depthf = datafile.final_depth\n",
    "    sectionf = datafile.final_section\n",
    "    zf = datafile.final_z\n",
    "    tempf = datafile.final_temp\n",
    "    \n",
    "    idx = np.where(sectionf==sectionnum)\n",
    "    transp_sec = transpf[idx]\n",
    "    lon_sec = lonf[idx]\n",
    "    depth_sec = depthf[idx]\n",
    "    zf_sec = zf[idx]\n",
    "    salt_sec = saltf[idx]\n",
    "    temp_sec = tempf[idx]\n",
    "    \n",
    "    return {'salt':salt_sec,'transport':transp_sec,'lon':lon_sec,'depth':depth_sec,'z':zf_sec,'temp':temp_sec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTS(axn,var,lonsec,zsec,varsec,lonW,lonE,depi,time,title,cblabel,ylabel,vmin=None,vmax=None):\n",
    "    \n",
    "    cmap = cm.deep\n",
    "    \n",
    "    m2lon = ((u_lons[lonE]-u_lons[lonW])/(mesh.e2f[0, latgridi, lonW:lonE].sum())).values #degrees/m\n",
    "    \n",
    "    arrw,xe,ye,im = axn.hist2d(lonsec/m2lon,df(zsec)[0],weights=varsec,cmap=cmap,bins=[np.array(f_lons[lonW:lonE:1]/m2lon),w_depths[0,0:depi]])\n",
    "    arrnw,xe2,ye2,im2 = axn.hist2d(lonsec/m2lon,df(zsec)[0],cmap=cmap,bins=[np.array(f_lons[lonW:lonE:1]/m2lon),w_depths[0,0:depi]])\n",
    "    \n",
    "    arr3 = arrw/arrnw\n",
    "    \n",
    "    X,Y = np.meshgrid(xe,ye)\n",
    "    \n",
    "    im = axn.pcolormesh(X,Y,arr3.T,vmin=vmin,vmax=vmax)\n",
    "    axn.set_xlabel('Longitude (°E)')\n",
    "    axn.set_title(title)\n",
    "    axn.invert_yaxis()\n",
    "    axn.set_xticks(np.linspace(f_lons[lonW]/m2lon,f_lons[lonE-1]/m2lon,4))\n",
    "    axn.set_xticklabels(['{:.2f}'.format(label) for label in np.linspace(f_lons[lonW],f_lons[lonE-1],4)])\n",
    "    \n",
    "    if cblabel == True:\n",
    "        cb = fig.colorbar(im,ax=axn)\n",
    "        \n",
    "        if var == 'temp':\n",
    "            cb.set_label('Temperature (°C)')\n",
    "        if var == 'sal':\n",
    "            cb.set_label('Salinity (g/kg)')\n",
    "            \n",
    "    if ylabel == True:\n",
    "        axn.set_ylabel('Depth (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datat(datafile,section, starttime, endtime):\n",
    "    final_section = datafile.final_section\n",
    "    final_transport = datafile.final_transp\n",
    "    transports = np.sum(np.where(final_section == section, final_transport, 0)) \n",
    "    return transports/(endtime-starttime+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/for_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "mesh = xr.open_dataset('/home/sallen/MEOPAR/grid/mesh_mask202108.nc')\n",
    "\n",
    "lonW = 308\n",
    "lonE = 327\n",
    "latgridi = 300\n",
    "latgridf = latgridi-1\n",
    "fmask = mesh.fmask[0, :, latgridi]\n",
    "tmask = mesh.tmask[0]\n",
    "    \n",
    "lons = data.init_lon[(data.final_section != 0)]\n",
    "    \n",
    "f_lons = mesh.glamf[0, latgridi]\n",
    "u_lons = mesh.glamv[0, latgridi]\n",
    "w_depths = mesh.gdepw_1d\n",
    "\n",
    "m2lon = ((u_lons[lonE]-u_lons[lonW])/(mesh.e2f[0, latgridi, lonW:lonE].sum())).values #degrees/m\n",
    "\n",
    "df = interp.interp1d(mesh.z,mesh.gdepw_1d) # Interpolate to get same binning scheme as SalishSeaCast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Forwards - Eastern JdF\n",
    "#Jan\n",
    "datafas = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/foradm_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafds = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/fordec_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafhsvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forharoVS_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafsjvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forsjcVS_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafrsvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forrosVS_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "#July\n",
    "datafas07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/foradm_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafds07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/fordec_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafhsvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forharoVS_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafsjvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forsjcVS_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafrsvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forrosVS_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/for_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "##Backwards\n",
    "databvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backVS_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databas = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backADM_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databds = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backdec_jan18/back_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databsjvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backsjcVS_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databrsvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backrosVS_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databhsvs = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backharoVS_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "#July\n",
    "databvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backVS_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databas07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backadm_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databds07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backdec_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databsjvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backsjcVS_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databrsvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backrosVS_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databhsvs07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backharoVS_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "##Forwards - SJGI\n",
    "# Jan\n",
    "datafg1 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forgulf1_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafg2 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forgulf2_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafhspr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forharoPR_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafsjpr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forsjcPR_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafrspr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forrosPR_jan18/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafpr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/for_jan18_PR/for_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "# Jul\n",
    "datafg107 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forgulf1_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafg207 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forgulf2_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafhspr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forharoPR_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafsjpr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forsjcPR_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafrspr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forrosPR_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "datafpr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/forPR_jul18/for_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "##Backwards\n",
    "# Jan\n",
    "databg1 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backgulf1_jan18/back_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databg2 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backgulf2_jan18/back_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databhspr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backharoPR_jan18/back_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databsjpr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backsjcPR_jan18/back_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databrspr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backrosPR_jan18/back_straight_01jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "databpr = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backPR_jan18/back_straight_28jan18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "# Jul\n",
    "databg107 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backgulf1_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databg207 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backgulf2_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databhspr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backharoPR_jul18/back_straight_01jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databsjpr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backsjcPR_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databrspr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backrosPR_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "databpr07 = xr.open_dataset('/ocean/cstang/MOAD/analysis-camryn/Ariane/backPR_jul18/back_straight_28jul18_s7t28/ariane_positions_quantitative.nc')\n",
    "\n",
    "data_dict = {'datafvs':data,'datafas':datafas,'datafds':datafds,'datafrsvs':datafrsvs,'datafsjvs':datafsjvs,'datafhsvs':datafhsvs,\n",
    "             'datafvs07':datafvs07,'datafas07':datafas07,'datafds07':datafds07,'datafrsvs07':datafrsvs07,'datafsjvs07':datafsjvs07,'datafhsvs07':datafhsvs07,\n",
    "             'databvs':databvs,'databas':databas,'databds':databds,'databrsvs':databrsvs,'databsjvs':databsjvs,'databhsvs':databhsvs,\n",
    "             'databvs07':databvs07,'databas07':databas07,'databds07':databds07,'databrsvs07':databrsvs07,'databsjvs07':databsjvs07,'databhsvs07':databhsvs07,\n",
    "             'datafpr':datafpr,'datafg1':datafg1,'datafg2':datafg2,'datafrspr':datafrspr,'datafsjpr':datafsjpr,'datafhspr':datafhspr,\n",
    "             'datafpr07':datafpr07,'datafg107':datafg107,'datafg207':datafg207,'datafrspr07':datafrspr07,'datafsjpr07':datafsjpr07,'datafhspr07':datafhspr07,\n",
    "             'databpr':databpr,'databg1':databg1,'databg2':databg2,'databrspr':databrspr,'databsjpr':databsjpr,'databhspr':databhspr,\n",
    "             'databpr07':databpr07,'databg107':databg107,'databg207':databg207,'databrspr07':databrspr07,'databsjpr07':databsjpr07,'databhspr07':databhspr07,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = 1\n",
    "endtime = 168\n",
    "\n",
    "sectionnum = [0,2,3,4,5,6]\n",
    "\n",
    "var = ['section_transpfvs','section_transpfas','section_transpfds','section_transpfrsvs','section_transpfsjvs','section_transpfhsvs',\n",
    "       'section_transpfvs07','section_transpfas07','section_transpfds07','section_transpfrsvs07','section_transpfsjvs07','section_transpfhsvs07',\n",
    "       'section_transpbvs','section_transpbas','section_transpbds','section_transpbrsvs','section_transpbsjvs','section_transpbhsvs',\n",
    "       'section_transpbvs07','section_transpbas07','section_transpbds07','section_transpbrsvs07','section_transpbsjvs07','section_transpbhsvs07',\n",
    "       'section_transpfpr','section_transpfg1','section_transpfg2','section_transpfrspr','section_transpfsjpr','section_transpfhspr',\n",
    "       'section_transpfpr07','section_transpfg107','section_transpfg207','section_transpfrspr07','section_transpfsjpr07','section_transpfhspr07',\n",
    "       'section_transpbpr','section_transpbg1','section_transpbg2','section_transpbrspr','section_transpbsjpr','section_transpbhspr',\n",
    "       'section_transpbpr07','section_transpbg107','section_transpbg207','section_transpbrspr07','section_transpbsjpr07','section_transpbhspr07',\n",
    "       ]\n",
    "data_name = ['datafvs','datafas','datafds','datafrsvs','datafsjvs','datafhsvs',\n",
    "             'datafvs07','datafas07','datafds07','datafrsvs07','datafsjvs07','datafhsvs07',\n",
    "             'databvs','databas','databds','databrsvs','databsjvs','databhsvs',\n",
    "             'databvs07','databas07','databds07','databrsvs07','databsjvs07','databhsvs07',\n",
    "             'datafpr','datafg1','datafg2','datafrspr','datafsjpr','datafhspr',\n",
    "             'datafpr07','datafg107','datafg207','datafrspr07','datafsjpr07','datafhspr07',\n",
    "             'databpr','databg1','databg2','databrspr','databsjpr','databhspr',\n",
    "             'databpr07','databg107','databg207','databrspr07','databsjpr07','databhspr07',\n",
    "             ]\n",
    "\n",
    "dict_sectiontransp = {}\n",
    "\n",
    "for i in range(len(var)):\n",
    "    variable_name = var[i]\n",
    "    \n",
    "    if variable_name not in dict_sectiontransp:\n",
    "        dict_sectiontransp[variable_name] = []\n",
    "    \n",
    "    for section in sectionnum:\n",
    "        dict_sectiontransp[variable_name].append(get_datat(data_dict[data_name[i]],section,starttime,endtime))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance - Eastern Juan de Fuca, Jan (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving VicSill: 115442.9414089004\n",
      "Leaving Admiralty: 46320.05326780694\n",
      "Leaving Haro: 83885.8340332499\n",
      "Leaving Rosario: 30763.5912555483\n",
      "Leaving San Juan: 18648.29773326977\n",
      "Leaving Deception: 2036.5138985505982\n",
      "Total: 297097.2315973259 \n",
      "\n",
      "Entering Victoria: 115677.48659706494\n",
      "Entering Admiralty: 42750.232752231015\n",
      "Entering Haro: 100828.87593089005\n",
      "Entering Rosario: 17590.059868435932\n",
      "Entering San Juan: 18917.95542585463\n",
      "Entering Deception: 1332.6210228493414\n",
      "Total: 297097.23159732594\n"
     ]
    }
   ],
   "source": [
    "leave_vic = np.sum(dict_sectiontransp['section_transpfvs'][1:])\n",
    "ent_vic = np.sum([dict_sectiontransp['section_transpfhsvs'][5],dict_sectiontransp['section_transpfsjvs'][4],dict_sectiontransp['section_transpfrsvs'][3],dict_sectiontransp['section_transpfds'][2],dict_sectiontransp['section_transpfas'][1]])\n",
    "\n",
    "leave_adm = np.sum(dict_sectiontransp['section_transpfas'][1:])\n",
    "ent_adm = np.sum([dict_sectiontransp['section_transpfvs'][1],dict_sectiontransp['section_transpfhsvs'][1],dict_sectiontransp['section_transpfsjvs'][1],dict_sectiontransp['section_transpfrsvs'][1],dict_sectiontransp['section_transpfds'][1]])\n",
    "\n",
    "leave_haro = np.sum(dict_sectiontransp['section_transpfhsvs'][1:])\n",
    "ent_haro = np.sum([dict_sectiontransp['section_transpfvs'][5],dict_sectiontransp['section_transpfas'][5],dict_sectiontransp['section_transpfds'][5],dict_sectiontransp['section_transpfrsvs'][5],dict_sectiontransp['section_transpfsjvs'][5]])\n",
    "\n",
    "leave_ros = np.sum(dict_sectiontransp['section_transpfrsvs'][1:])\n",
    "ent_ros = np.sum([dict_sectiontransp['section_transpfvs'][3],dict_sectiontransp['section_transpfas'][3],dict_sectiontransp['section_transpfds'][3],dict_sectiontransp['section_transpfsjvs'][3],dict_sectiontransp['section_transpfhsvs'][3]])\n",
    "\n",
    "leave_sjc = np.sum(dict_sectiontransp['section_transpfsjvs'][1:])\n",
    "ent_sjc = np.sum([dict_sectiontransp['section_transpfvs'][4],dict_sectiontransp['section_transpfas'][4],dict_sectiontransp['section_transpfds'][4],dict_sectiontransp['section_transpfrsvs'][4],dict_sectiontransp['section_transpfhsvs'][4]])\n",
    "\n",
    "leave_dec = np.sum(dict_sectiontransp['section_transpfds'][1:])\n",
    "ent_dec = np.sum([dict_sectiontransp['section_transpfvs'][2],dict_sectiontransp['section_transpfas'][2],dict_sectiontransp['section_transpfrsvs'][2],dict_sectiontransp['section_transpfsjvs'][2],dict_sectiontransp['section_transpfhsvs'][2]])\n",
    "\n",
    "leave_total = np.sum([leave_haro,leave_vic,leave_ros,leave_sjc,leave_dec,leave_adm])\n",
    "ent_total = np.sum([ent_haro,ent_vic,ent_adm,ent_dec,ent_ros,ent_sjc])\n",
    "\n",
    "print('Leaving VicSill:',leave_vic)\n",
    "print('Leaving Admiralty:',leave_adm)\n",
    "print('Leaving Haro:',leave_haro)\n",
    "print('Leaving Rosario:',leave_ros)\n",
    "print('Leaving San Juan:',leave_sjc)\n",
    "print('Leaving Deception:',leave_dec)\n",
    "print('Total:',leave_total,'\\n')\n",
    "\n",
    "print('Entering Victoria:',ent_vic)\n",
    "print('Entering Admiralty:',ent_adm)\n",
    "print('Entering Haro:',ent_haro)\n",
    "print('Entering Rosario:',ent_ros)\n",
    "print('Entering San Juan:',ent_sjc)\n",
    "print('Entering Deception:',ent_dec)\n",
    "print('Total:',ent_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance - Eastern Juan de Fuca, July (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving VicSill: 143789.43111006363\n",
      "Leaving Admiralty: 39007.37415168765\n",
      "Leaving Haro: 82594.40970816233\n",
      "Leaving Rosario: 55141.46214215933\n",
      "Leaving San Juan: 21489.6065426656\n",
      "Leaving Deception: 1470.9167118085136\n",
      "Total: 343493.20036654704 \n",
      "\n",
      "Entering Victoria: 161743.18112842017\n",
      "Entering Admiralty: 38331.41840890986\n",
      "Entering Haro: 115976.44535501253\n",
      "Entering Rosario: 14912.80799921974\n",
      "Entering San Juan: 11778.822581549859\n",
      "Entering Deception: 750.5248934348705\n",
      "Total: 343493.2003665471\n"
     ]
    }
   ],
   "source": [
    "leave_vic = np.sum(dict_sectiontransp['section_transpfvs07'][1:])\n",
    "ent_vic = np.sum([dict_sectiontransp['section_transpfhsvs07'][5],dict_sectiontransp['section_transpfsjvs07'][4],dict_sectiontransp['section_transpfrsvs07'][3],dict_sectiontransp['section_transpfds07'][2],dict_sectiontransp['section_transpfas07'][1]])\n",
    "\n",
    "leave_adm = np.sum(dict_sectiontransp['section_transpfas07'][1:])\n",
    "ent_adm = np.sum([dict_sectiontransp['section_transpfvs07'][1],dict_sectiontransp['section_transpfhsvs07'][1],dict_sectiontransp['section_transpfsjvs07'][1],dict_sectiontransp['section_transpfrsvs07'][1],dict_sectiontransp['section_transpfds07'][1]])\n",
    "\n",
    "leave_haro = np.sum(dict_sectiontransp['section_transpfhsvs07'][1:])\n",
    "ent_haro = np.sum([dict_sectiontransp['section_transpfvs07'][5],dict_sectiontransp['section_transpfas07'][5],dict_sectiontransp['section_transpfds07'][5],dict_sectiontransp['section_transpfrsvs07'][5],dict_sectiontransp['section_transpfsjvs07'][5]])\n",
    "\n",
    "leave_ros = np.sum(dict_sectiontransp['section_transpfrsvs07'][1:])\n",
    "ent_ros = np.sum([dict_sectiontransp['section_transpfvs07'][3],dict_sectiontransp['section_transpfas07'][3],dict_sectiontransp['section_transpfds07'][3],dict_sectiontransp['section_transpfsjvs07'][3],dict_sectiontransp['section_transpfhsvs07'][3]])\n",
    "\n",
    "leave_sjc = np.sum(dict_sectiontransp['section_transpfsjvs07'][1:])\n",
    "ent_sjc = np.sum([dict_sectiontransp['section_transpfvs07'][4],dict_sectiontransp['section_transpfas07'][4],dict_sectiontransp['section_transpfds07'][4],dict_sectiontransp['section_transpfrsvs07'][4],dict_sectiontransp['section_transpfhsvs07'][4]])\n",
    "\n",
    "leave_dec = np.sum(dict_sectiontransp['section_transpfds07'][1:])\n",
    "ent_dec = np.sum([dict_sectiontransp['section_transpfvs07'][2],dict_sectiontransp['section_transpfas07'][2],dict_sectiontransp['section_transpfrsvs07'][2],dict_sectiontransp['section_transpfsjvs07'][2],dict_sectiontransp['section_transpfhsvs07'][2]])\n",
    "\n",
    "leave_total = np.sum([leave_haro,leave_vic,leave_ros,leave_sjc,leave_dec,leave_adm])\n",
    "ent_total = np.sum([ent_haro,ent_vic,ent_adm,ent_dec,ent_ros,ent_sjc])\n",
    "\n",
    "print('Leaving VicSill:',leave_vic)\n",
    "print('Leaving Admiralty:',leave_adm)\n",
    "print('Leaving Haro:',leave_haro)\n",
    "print('Leaving Rosario:',leave_ros)\n",
    "print('Leaving San Juan:',leave_sjc)\n",
    "print('Leaving Deception:',leave_dec)\n",
    "print('Total:',leave_total,'\\n')\n",
    "\n",
    "print('Entering Victoria:',ent_vic)\n",
    "print('Entering Admiralty:',ent_adm)\n",
    "print('Entering Haro:',ent_haro)\n",
    "print('Entering Rosario:',ent_ros)\n",
    "print('Entering San Juan:',ent_sjc)\n",
    "print('Entering Deception:',ent_dec)\n",
    "print('Total:',ent_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance - Eastern Juan de Fuca, July (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving VicSill: 69775.01367985812\n",
      "Leaving Admiralty: 33274.63536649126\n",
      "Leaving Haro: 52429.9331715027\n",
      "Leaving Rosario: 8982.600916157924\n",
      "Leaving San Juan: 13603.718251741293\n",
      "Leaving Deception: 1894.4070192909705\n",
      "Total: 179960.30840504222 \n",
      "\n",
      "Entering Victoria: 64195.62377027394\n",
      "Entering Admiralty: 28874.556372477015\n",
      "Entering Haro: 56909.77481054612\n",
      "Entering Rosario: 16402.42651761673\n",
      "Entering San Juan: 13295.025179388338\n",
      "Entering Deception: 282.9017547401383\n",
      "Total: 179960.30840504228\n"
     ]
    }
   ],
   "source": [
    "leave_vic = np.sum(dict_sectiontransp['section_transpbvs'][1:])\n",
    "ent_vic = np.sum([dict_sectiontransp['section_transpbhsvs'][5],dict_sectiontransp['section_transpbsjvs'][4],dict_sectiontransp['section_transpbrsvs'][3],dict_sectiontransp['section_transpbds'][2],dict_sectiontransp['section_transpbas'][1]])\n",
    "\n",
    "leave_adm = np.sum(dict_sectiontransp['section_transpbas'][1:])\n",
    "ent_adm = np.sum([dict_sectiontransp['section_transpbvs'][1],dict_sectiontransp['section_transpbhsvs'][1],dict_sectiontransp['section_transpbsjvs'][1],dict_sectiontransp['section_transpbrsvs'][1],dict_sectiontransp['section_transpbds'][1]])\n",
    "\n",
    "leave_haro = np.sum(dict_sectiontransp['section_transpbhsvs'][1:])\n",
    "ent_haro = np.sum([dict_sectiontransp['section_transpbvs'][5],dict_sectiontransp['section_transpbas'][5],dict_sectiontransp['section_transpbds'][5],dict_sectiontransp['section_transpbrsvs'][5],dict_sectiontransp['section_transpbsjvs'][5]])\n",
    "\n",
    "leave_ros = np.sum(dict_sectiontransp['section_transpbrsvs'][1:])\n",
    "ent_ros = np.sum([dict_sectiontransp['section_transpbvs'][3],dict_sectiontransp['section_transpbas'][3],dict_sectiontransp['section_transpbds'][3],dict_sectiontransp['section_transpbsjvs'][3],dict_sectiontransp['section_transpbhsvs'][3]])\n",
    "\n",
    "leave_sjc = np.sum(dict_sectiontransp['section_transpbsjvs'][1:])\n",
    "ent_sjc = np.sum([dict_sectiontransp['section_transpbvs'][4],dict_sectiontransp['section_transpbas'][4],dict_sectiontransp['section_transpbds'][4],dict_sectiontransp['section_transpbrsvs'][4],dict_sectiontransp['section_transpbhsvs'][4]])\n",
    "\n",
    "leave_dec = np.sum(dict_sectiontransp['section_transpbds'][1:])\n",
    "ent_dec = np.sum([dict_sectiontransp['section_transpbvs'][2],dict_sectiontransp['section_transpbas'][2],dict_sectiontransp['section_transpbrsvs'][2],dict_sectiontransp['section_transpbsjvs'][2],dict_sectiontransp['section_transpbhsvs'][2]])\n",
    "\n",
    "leave_total = np.sum([leave_haro,leave_vic,leave_ros,leave_sjc,leave_dec,leave_adm])\n",
    "ent_total = np.sum([ent_haro,ent_vic,ent_adm,ent_dec,ent_ros,ent_sjc])\n",
    "\n",
    "print('Leaving VicSill:',leave_vic)\n",
    "print('Leaving Admiralty:',leave_adm)\n",
    "print('Leaving Haro:',leave_haro)\n",
    "print('Leaving Rosario:',leave_ros)\n",
    "print('Leaving San Juan:',leave_sjc)\n",
    "print('Leaving Deception:',leave_dec)\n",
    "print('Total:',leave_total,'\\n')\n",
    "\n",
    "print('Entering Victoria:',ent_vic)\n",
    "print('Entering Admiralty:',ent_adm)\n",
    "print('Entering Haro:',ent_haro)\n",
    "print('Entering Rosario:',ent_ros)\n",
    "print('Entering San Juan:',ent_sjc)\n",
    "print('Entering Deception:',ent_dec)\n",
    "print('Total:',ent_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance - SJGI, Jan (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving Haro: 46570.24167264905\n",
      "Leaving SanJuan:  5550.4500176716865\n",
      "Leaving Rosario: 4623.476834830786\n",
      "Leaving PointRob: 35542.598489668446\n",
      "Leaving Gulf1: 10694.064688829832\n",
      "Leaving Gulf2: 3830.6871710463574\n",
      "Total 106811.51887469615 \n",
      "\n",
      "Entering Haro: 33242.74294482853\n",
      "Entering SanJuan:  7059.222178079723\n",
      "Entering Rosario: 17614.23125150292\n",
      "Entering PointRob: 36272.978528579\n",
      "Entering Gulf1: 8672.954445048696\n",
      "Entering Gulf2: 3949.389526657297\n",
      "Total 106811.51887469616\n"
     ]
    }
   ],
   "source": [
    "leave_haro = np.sum(dict_sectiontransp['section_transpfhspr'][1:])\n",
    "leave_sjc = np.sum(dict_sectiontransp['section_transpfsjpr'][1:])\n",
    "leave_ros = np.sum(dict_sectiontransp['section_transpfrspr'][1:])\n",
    "leave_pr = np.sum(dict_sectiontransp['section_transpfpr'][1:])\n",
    "leave_g1 = np.sum(dict_sectiontransp['section_transpfg1'][1:])\n",
    "leave_g2 = np.sum(dict_sectiontransp['section_transpfg2'][1:])\n",
    "leave_total = np.sum([leave_haro,leave_sjc,leave_ros,leave_pr,leave_g1,leave_g2])\n",
    "\n",
    "ent_haro = np.sum([dict_sectiontransp['section_transpfsjpr'][5],dict_sectiontransp['section_transpfrspr'][5],dict_sectiontransp['section_transpfpr'][5],dict_sectiontransp['section_transpfg1'][5],dict_sectiontransp['section_transpfg2'][5]])\n",
    "ent_pr = np.sum([dict_sectiontransp['section_transpfhspr'][5],dict_sectiontransp['section_transpfsjpr'][4],dict_sectiontransp['section_transpfrspr'][3],dict_sectiontransp['section_transpfg1'][1],dict_sectiontransp['section_transpfg2'][2]])\n",
    "ent_sjc = np.sum([dict_sectiontransp['section_transpfhspr'][4],dict_sectiontransp['section_transpfrspr'][4],dict_sectiontransp['section_transpfpr'][4],dict_sectiontransp['section_transpfg1'][4],dict_sectiontransp['section_transpfg2'][4]])\n",
    "ent_ros = np.sum([dict_sectiontransp['section_transpfsjpr'][3],dict_sectiontransp['section_transpfhspr'][3],dict_sectiontransp['section_transpfpr'][3],dict_sectiontransp['section_transpfg1'][3],dict_sectiontransp['section_transpfg2'][3]])\n",
    "ent_g1 = np.sum([dict_sectiontransp['section_transpfsjpr'][1],dict_sectiontransp['section_transpfrspr'][1],dict_sectiontransp['section_transpfpr'][1],dict_sectiontransp['section_transpfhspr'][1],dict_sectiontransp['section_transpfg2'][1]])\n",
    "ent_g2 = np.sum([dict_sectiontransp['section_transpfsjpr'][2],dict_sectiontransp['section_transpfrspr'][2],dict_sectiontransp['section_transpfpr'][2],dict_sectiontransp['section_transpfg1'][2],dict_sectiontransp['section_transpfhspr'][2]])\n",
    "\n",
    "ent_total = np.sum([ent_haro,ent_pr,ent_ros,ent_sjc,ent_g1,ent_g2])\n",
    "\n",
    "print('Leaving Haro:',leave_haro)\n",
    "print('Leaving SanJuan: ',leave_sjc)\n",
    "print('Leaving Rosario:',leave_ros)\n",
    "print('Leaving PointRob:',leave_pr)\n",
    "print('Leaving Gulf1:',leave_g1)\n",
    "print('Leaving Gulf2:',leave_g2)\n",
    "print('Total',leave_total,'\\n')\n",
    "\n",
    "print('Entering Haro:',ent_haro)\n",
    "print('Entering SanJuan: ',ent_sjc)\n",
    "print('Entering Rosario:',ent_ros)\n",
    "print('Entering PointRob:',ent_pr)\n",
    "print('Entering Gulf1:',ent_g1)\n",
    "print('Entering Gulf2:',ent_g2)\n",
    "print('Total',ent_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance - SJGI, July (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving Haro: 73549.9920240067\n",
      "Leaving SanJuan:  2965.7887606488803\n",
      "Leaving Rosario: 270.3993197320528\n",
      "Leaving PointRob: 55291.629419941775\n",
      "Leaving Gulf1: 9602.536076155557\n",
      "Leaving Gulf2: 3387.4114142240846\n",
      "Total 145067.75701470903 \n",
      "\n",
      "Entering Haro: 37772.173063457034\n",
      "Entering SanJuan:  10842.133387725988\n",
      "Entering Rosario: 31249.15103220599\n",
      "Entering PointRob: 54367.46843558952\n",
      "Entering Gulf1: 8734.226151764347\n",
      "Entering Gulf2: 2102.60494396616\n",
      "Total 145067.75701470903\n"
     ]
    }
   ],
   "source": [
    "leave_haro = np.sum(dict_sectiontransp['section_transpfhspr07'][1:])\n",
    "leave_sjc = np.sum(dict_sectiontransp['section_transpfsjpr07'][1:])\n",
    "leave_ros = np.sum(dict_sectiontransp['section_transpfrspr07'][1:])\n",
    "leave_pr = np.sum(dict_sectiontransp['section_transpfpr07'][1:])\n",
    "leave_g1 = np.sum(dict_sectiontransp['section_transpfg107'][1:])\n",
    "leave_g2 = np.sum(dict_sectiontransp['section_transpfg207'][1:])\n",
    "leave_total = np.sum([leave_haro,leave_sjc,leave_ros,leave_pr,leave_g1,leave_g2])\n",
    "\n",
    "ent_haro = np.sum([dict_sectiontransp['section_transpfsjpr07'][5],dict_sectiontransp['section_transpfrspr07'][5],dict_sectiontransp['section_transpfpr07'][5],dict_sectiontransp['section_transpfg107'][5],dict_sectiontransp['section_transpfg207'][5]])\n",
    "ent_pr = np.sum([dict_sectiontransp['section_transpfhspr07'][5],dict_sectiontransp['section_transpfsjpr07'][4],dict_sectiontransp['section_transpfrspr07'][3],dict_sectiontransp['section_transpfg107'][1],dict_sectiontransp['section_transpfg207'][2]])\n",
    "ent_sjc = np.sum([dict_sectiontransp['section_transpfhspr07'][4],dict_sectiontransp['section_transpfrspr07'][4],dict_sectiontransp['section_transpfpr07'][4],dict_sectiontransp['section_transpfg107'][4],dict_sectiontransp['section_transpfg207'][4]])\n",
    "ent_ros = np.sum([dict_sectiontransp['section_transpfsjpr07'][3],dict_sectiontransp['section_transpfhspr07'][3],dict_sectiontransp['section_transpfpr07'][3],dict_sectiontransp['section_transpfg107'][3],dict_sectiontransp['section_transpfg207'][3]])\n",
    "ent_g1 = np.sum([dict_sectiontransp['section_transpfsjpr07'][1],dict_sectiontransp['section_transpfrspr07'][1],dict_sectiontransp['section_transpfpr07'][1],dict_sectiontransp['section_transpfhspr07'][1],dict_sectiontransp['section_transpfg207'][1]])\n",
    "ent_g2 = np.sum([dict_sectiontransp['section_transpfsjpr07'][2],dict_sectiontransp['section_transpfrspr07'][2],dict_sectiontransp['section_transpfpr07'][2],dict_sectiontransp['section_transpfg107'][2],dict_sectiontransp['section_transpfhspr07'][2]])\n",
    "\n",
    "ent_total = np.sum([ent_haro,ent_pr,ent_ros,ent_sjc,ent_g1,ent_g2])\n",
    "\n",
    "print('Leaving Haro:',leave_haro)\n",
    "print('Leaving SanJuan: ',leave_sjc)\n",
    "print('Leaving Rosario:',leave_ros)\n",
    "print('Leaving PointRob:',leave_pr)\n",
    "print('Leaving Gulf1:',leave_g1)\n",
    "print('Leaving Gulf2:',leave_g2)\n",
    "print('Total',leave_total,'\\n')\n",
    "\n",
    "print('Entering Haro:',ent_haro)\n",
    "print('Entering SanJuan: ',ent_sjc)\n",
    "print('Entering Rosario:',ent_ros)\n",
    "print('Entering PointRob:',ent_pr)\n",
    "print('Entering Gulf1:',ent_g1)\n",
    "print('Entering Gulf2:',ent_g2)\n",
    "print('Total',ent_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101992.0359021202, 31376.8941213031, 13.456059159455611, 2470.603053432186, 1859.0735586814149, 10600.026475230792]\n",
      "[71463.43953919351, 3467.007507138596, 1659.1203502073604, 3197.3575903872734, 1555.2649157938893, 702.2368033838187]\n"
     ]
    }
   ],
   "source": [
    "print(dict_sectiontransp['section_transpfas'])\n",
    "print(dict_sectiontransp['section_transpbrsvs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('analysis-camryn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45037fb5df905fe0ec215a1f079d5355b535b26f32fb585b4920c91cfb7d4d84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
